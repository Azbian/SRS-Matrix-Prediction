{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "adea31ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import ast\n",
    "from tensorflow.keras import layers, models\n",
    "\n",
    "# --- 1. The Multi-Rate Sliding Window Generator ---\n",
    "def combined_generator(e2_csv, srs_csv, e2_len=20, srs_input_rows=100, pred_offset=50):\n",
    "    # Load E2\n",
    "    df_e2 = pd.read_csv(e2_csv, header=None).apply(pd.to_numeric, errors='coerce').fillna(0)\n",
    "\n",
    "    # Load and Parse SRS\n",
    "    df_srs = pd.read_csv(srs_csv, header=None)\n",
    "    parsed_srs = []\n",
    "    for val in df_srs[0]:\n",
    "        raw_arr = np.array(ast.literal_eval(val), dtype=np.float32)\n",
    "        arr_reshaped = raw_arr.T.reshape(4, 1536)\n",
    "        parsed_srs.append(arr_reshaped)\n",
    "    srs_data = np.stack(parsed_srs, axis=0)\n",
    "\n",
    "    # We determine steps based on the SRS file because it's the jumping one\n",
    "    # If SRS jumps by 50, we can only take as many steps as SRS allows\n",
    "    total_srs_needed_per_step = 100 + pred_offset # 150\n",
    "    # max_t * 50 + 150 <= total_srs\n",
    "    num_steps_srs = (len(srs_data) - total_srs_needed_per_step) // 50\n",
    "\n",
    "    # Also check E2 length\n",
    "    num_steps_e2 = len(df_e2) - e2_len\n",
    "\n",
    "    num_steps = min(num_steps_e2, num_steps_srs)\n",
    "\n",
    "    for t in range(num_steps):\n",
    "        # --- E2 Input: Slides 1 by 1 ---\n",
    "        e2_chunk = df_e2.iloc[t : t + e2_len, :19].values\n",
    "        flat_e2 = np.zeros(5 * 4 * 19, dtype=np.float32)\n",
    "        flat_e2[:min(e2_chunk.size, 380)] = e2_chunk.flatten()[:380]\n",
    "        X_e2 = flat_e2.reshape(5, 4, 19)\n",
    "\n",
    "        # --- SRS Input: Jumps by 50 ---\n",
    "        srs_start = t * 50\n",
    "        srs_end = srs_start + srs_input_rows\n",
    "        X_srs_window = srs_data[srs_start : srs_end] # (100, 4, 1536)\n",
    "        X_srs = X_srs_window.reshape(20, 20, 1536)\n",
    "\n",
    "        # --- Label: 50 steps after the SRS window ends ---\n",
    "        label_idx = srs_end + pred_offset - 1\n",
    "        y = srs_data[label_idx]\n",
    "\n",
    "        yield (X_e2, X_srs), y\n",
    "\n",
    "def test_generator(e2_test_path, srs_test_path, e2_len=20, srs_input_rows=100, pred_offset=50):\n",
    "    # Load Test Data\n",
    "    df_e2 = pd.read_csv(e2_test_path, header=None).apply(pd.to_numeric, errors='coerce').fillna(0)\n",
    "    df_srs = pd.read_csv(srs_test_path, header=None)\n",
    "    \n",
    "    parsed_srs = []\n",
    "    for val in df_srs[0]:\n",
    "        raw_arr = np.array(ast.literal_eval(val), dtype=np.float32)\n",
    "        parsed_srs.append(raw_arr.T.reshape(4, 1536))\n",
    "    srs_data = np.stack(parsed_srs, axis=0)\n",
    "\n",
    "    num_steps = min(len(df_e2) - e2_len, (len(srs_data) - (100 + pred_offset)) // 50)\n",
    "\n",
    "    for t in range(num_steps):\n",
    "        # E2 Window\n",
    "        e2_chunk = df_e2.iloc[t : t + e2_len, :19].values\n",
    "        X_e2 = np.zeros(380, dtype=np.float32)\n",
    "        X_e2[:e2_chunk.size] = e2_chunk.flatten()[:380]\n",
    "        X_e2 = X_e2.reshape(5, 4, 19)\n",
    "\n",
    "        # SRS Window (Jumping by 50)\n",
    "        srs_start = t * 50\n",
    "        X_srs = srs_data[srs_start : srs_start + 100].reshape(20, 20, 1536)\n",
    "\n",
    "        # Ground Truth Label\n",
    "        y_true = srs_data[srs_start + 100 + pred_offset - 1]\n",
    "\n",
    "        yield (X_e2, X_srs), y_true\n",
    "\n",
    "def get_dataset(e2_list, srs_list, batch_size=4):\n",
    "    output_signature = (\n",
    "        (\n",
    "            tf.TensorSpec(shape=(5, 4, 19), dtype=tf.float32), \n",
    "            tf.TensorSpec(shape=(20, 20, 1536), dtype=tf.float32)\n",
    "        ),\n",
    "        tf.TensorSpec(shape=(4, 1536), dtype=tf.float32)\n",
    "    )\n",
    "\n",
    "    ds = tf.data.Dataset.from_generator(\n",
    "        lambda: combined_generator(e2_list, srs_list),\n",
    "        output_signature=output_signature\n",
    "    )\n",
    "    \n",
    "    # NO SHUFFLE - maintains the exact timeline of the CSVs\n",
    "    return ds.batch(batch_size).prefetch(tf.data.AUTOTUNE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0f73f1e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers, models\n",
    "\n",
    "def create_model(e2_input_shape=(5, 4, 19), srs_input_shape=(20, 20, 1536), lstm_units=128, dropout_rate=0.3):\n",
    "    \n",
    "    radio_input = layers.Input(shape=e2_input_shape, name='radio_input')\n",
    "    \n",
    "    r1 = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(radio_input)  # use padded r1\n",
    "    r1 = layers.BatchNormalization()(r1)\n",
    "    r1 = layers.Conv2D(32, (2, 2), activation='relu', padding='same')(r1)\n",
    "    r1 = layers.BatchNormalization()(r1)\n",
    "    r1 = layers.Dropout(dropout_rate)(r1)\n",
    "    r1 = layers.ZeroPadding2D(padding=((0,0),(0,1)))(r1)  # pad width by 1\n",
    "\n",
    "    srs_input = layers.Input(shape=srs_input_shape, name='srs_input')\n",
    "    s1 = layers.Conv2D(1024, (3, 3), activation='relu', padding='same')(srs_input)\n",
    "    s1 = layers.BatchNormalization()(s1)\n",
    "    s1 = layers.MaxPooling2D((2, 2))(s1)\n",
    "    s1 = layers.Conv2D(512, (1, 1), activation='relu', padding='same')(s1)\n",
    "    s1 = layers.Conv2D(256, (2, 2), activation='relu', padding='same')(s1)\n",
    "    s1 = layers.Conv2D(512, (2, 2), activation='relu', padding='same')(s1)\n",
    "    s1 = layers.BatchNormalization()(s1)\n",
    "    s1 = layers.MaxPooling2D((2, 2))(s1)\n",
    "    s1 = layers.Conv2D(256, (1, 1), activation='relu', padding='same')(s1)\n",
    "    s1 = layers.Conv2D(128, (1, 1), activation='relu', padding='same')(s1)\n",
    "    s1 = layers.Dropout(dropout_rate)(s1)\n",
    "\n",
    "    # Concatenate and LSTM\n",
    "    x = layers.Concatenate(axis=-1)([r1, s1])\n",
    "    x = layers.Reshape((5*5, 32+128))(x)\n",
    "    x = layers.LSTM(lstm_units, return_sequences=True)(x)\n",
    "    x = layers.Flatten()(x)         \n",
    "    x = layers.Dense(4*1536)(x)      \n",
    "    output = layers.Reshape((4,1536))(x)\n",
    "\n",
    "    model = models.Model(inputs=[radio_input, srs_input], outputs=output)\n",
    "    model.compile(optimizer='adam', loss='mse')\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "96b4623f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " srs_input (InputLayer)         [(None, 20, 20, 153  0           []                               \n",
      "                                6)]                                                               \n",
      "                                                                                                  \n",
      " conv2d_2 (Conv2D)              (None, 20, 20, 1024  14156800    ['srs_input[0][0]']              \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_2 (BatchNo  (None, 20, 20, 1024  4096       ['conv2d_2[0][0]']               \n",
      " rmalization)                   )                                                                 \n",
      "                                                                                                  \n",
      " max_pooling2d (MaxPooling2D)   (None, 10, 10, 1024  0           ['batch_normalization_2[0][0]']  \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_3 (Conv2D)              (None, 10, 10, 512)  524800      ['max_pooling2d[0][0]']          \n",
      "                                                                                                  \n",
      " radio_input (InputLayer)       [(None, 5, 4, 19)]   0           []                               \n",
      "                                                                                                  \n",
      " conv2d_4 (Conv2D)              (None, 10, 10, 256)  524544      ['conv2d_3[0][0]']               \n",
      "                                                                                                  \n",
      " conv2d (Conv2D)                (None, 5, 4, 64)     11008       ['radio_input[0][0]']            \n",
      "                                                                                                  \n",
      " conv2d_5 (Conv2D)              (None, 10, 10, 512)  524800      ['conv2d_4[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization (BatchNorm  (None, 5, 4, 64)    256         ['conv2d[0][0]']                 \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " batch_normalization_3 (BatchNo  (None, 10, 10, 512)  2048       ['conv2d_5[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv2d_1 (Conv2D)              (None, 5, 4, 32)     8224        ['batch_normalization[0][0]']    \n",
      "                                                                                                  \n",
      " max_pooling2d_1 (MaxPooling2D)  (None, 5, 5, 512)   0           ['batch_normalization_3[0][0]']  \n",
      "                                                                                                  \n",
      " batch_normalization_1 (BatchNo  (None, 5, 4, 32)    128         ['conv2d_1[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv2d_6 (Conv2D)              (None, 5, 5, 256)    131328      ['max_pooling2d_1[0][0]']        \n",
      "                                                                                                  \n",
      " dropout (Dropout)              (None, 5, 4, 32)     0           ['batch_normalization_1[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_7 (Conv2D)              (None, 5, 5, 128)    32896       ['conv2d_6[0][0]']               \n",
      "                                                                                                  \n",
      " zero_padding2d (ZeroPadding2D)  (None, 5, 5, 32)    0           ['dropout[0][0]']                \n",
      "                                                                                                  \n",
      " dropout_1 (Dropout)            (None, 5, 5, 128)    0           ['conv2d_7[0][0]']               \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 5, 5, 160)    0           ['zero_padding2d[0][0]',         \n",
      "                                                                  'dropout_1[0][0]']              \n",
      "                                                                                                  \n",
      " reshape (Reshape)              (None, 25, 160)      0           ['concatenate[0][0]']            \n",
      "                                                                                                  \n",
      " lstm (LSTM)                    (None, 25, 128)      147968      ['reshape[0][0]']                \n",
      "                                                                                                  \n",
      " flatten (Flatten)              (None, 3200)         0           ['lstm[0][0]']                   \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 6144)         19666944    ['flatten[0][0]']                \n",
      "                                                                                                  \n",
      " reshape_1 (Reshape)            (None, 4, 1536)      0           ['dense[0][0]']                  \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 35,735,840\n",
      "Trainable params: 35,732,576\n",
      "Non-trainable params: 3,264\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/15\n",
      "106/106 [==============================] - 544s 87ms/step - loss: 4872.0781\n",
      "Epoch 2/15\n",
      "106/106 [==============================] - 546s 68ms/step - loss: 4869.5596\n",
      "Epoch 3/15\n",
      "106/106 [==============================] - 548s 67ms/step - loss: 4857.8662\n",
      "Epoch 4/15\n",
      "106/106 [==============================] - 547s 67ms/step - loss: 4842.4062\n",
      "Epoch 5/15\n",
      "106/106 [==============================] - 575s 67ms/step - loss: 4825.1333\n",
      "Epoch 6/15\n",
      "106/106 [==============================] - 553s 66ms/step - loss: 4809.2754\n",
      "Epoch 7/15\n",
      "106/106 [==============================] - 577s 66ms/step - loss: 4770.0020\n",
      "Epoch 8/15\n",
      "106/106 [==============================] - 535s 67ms/step - loss: 4725.2427\n",
      "Epoch 9/15\n",
      "106/106 [==============================] - 559s 67ms/step - loss: 4672.6997\n",
      "Epoch 10/15\n",
      "106/106 [==============================] - 547s 66ms/step - loss: 4589.8511\n",
      "Epoch 11/15\n",
      "106/106 [==============================] - 541s 67ms/step - loss: 4530.3560\n",
      "Epoch 12/15\n",
      "106/106 [==============================] - 559s 66ms/step - loss: 4462.5381\n",
      "Epoch 13/15\n",
      "106/106 [==============================] - 562s 67ms/step - loss: 4378.6465\n",
      "Epoch 14/15\n",
      "106/106 [==============================] - 555s 66ms/step - loss: 4277.1802\n",
      "Epoch 15/15\n",
      "106/106 [==============================] - 560s 67ms/step - loss: 4232.1655\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x157afda6ad0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "model = create_model()\n",
    "model.summary()\n",
    "\n",
    "train_ds = get_dataset(\n",
    "    \"P:/SP Challenge/DataSet/Preprocessed Dataset/combined_E2.csv\", \n",
    "    \"P:/SP Challenge/DataSet/Preprocessed Dataset/combined_pp_srs.csv\",\n",
    "    batch_size=2\n",
    ")\n",
    "model.fit(train_ds, epochs=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "354d2350",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51/51 [==============================] - 137s 27ms/step - loss: 6722.2090\n",
      "Test MSE: 6722.208984375\n",
      "51/51 [==============================] - 147s 27ms/step\n"
     ]
    }
   ],
   "source": [
    "\n",
    "test_ds = tf.data.Dataset.from_generator(\n",
    "    lambda: test_generator(\"P:/SP Challenge/DataSet/Preprocessed Dataset/E2_1.csv\", \n",
    "                           \"P:/SP Challenge/DataSet/Preprocessed Dataset/pp_srs_1.csv\"),\n",
    "    output_signature=(\n",
    "        (tf.TensorSpec(shape=(5, 4, 19), dtype=tf.float32), \n",
    "         tf.TensorSpec(shape=(20, 20, 1536), dtype=tf.float32)),\n",
    "        tf.TensorSpec(shape=(4, 1536), dtype=tf.float32)\n",
    "    )\n",
    ").batch(1)\n",
    "\n",
    "test_loss = model.evaluate(test_ds)\n",
    "print(f\"Test MSE: {test_loss}\")\n",
    "\n",
    "predictions = model.predict(test_ds)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
