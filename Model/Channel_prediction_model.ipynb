{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "adea31ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def load_e2_chunk(csv_file, start_row, num_rows=20, channels=19):\n",
    "    \"\"\"\n",
    "    Reads a CSV file and fetches `num_rows` starting from `start_row`,\n",
    "    reshapes into WxHxC for CNN input. Non-numeric values are replaced with 0.\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(csv_file, header=None)\n",
    "    \n",
    "    # Convert all to numeric, replace errors with 0\n",
    "    df = df.apply(pd.to_numeric, errors='coerce').fillna(0)\n",
    "    \n",
    "    data_chunk = df.iloc[start_row:start_row + num_rows, :channels].values  # shape: (num_rows, channels)\n",
    "    \n",
    "    # WxH grid\n",
    "    W = 5\n",
    "    H = 4\n",
    "    \n",
    "    # Check if padding is needed\n",
    "    total_elements = W * H\n",
    "    flat_data = data_chunk.flatten()  # shape: num_rows*channels\n",
    "    if flat_data.size < total_elements * channels:\n",
    "        padded = np.zeros(total_elements * channels)\n",
    "        padded[:flat_data.size] = flat_data\n",
    "    else:\n",
    "        padded = flat_data[:total_elements * channels]  # truncate if larger\n",
    "    \n",
    "    # Reshape into WxHxC\n",
    "    grid = padded.reshape(W, H, channels)\n",
    "    \n",
    "    return grid.astype(np.float32)  # final shape: 5x4xC\n",
    "\n",
    "\n",
    "def load_srs_chunk(csv_path, input_rows=70, pred_offset=5, W=20, H=14):\n",
    "    \"\"\"\n",
    "    Sliding window SRS generator.\n",
    "    \n",
    "    Each CSV row contains a string representation of a list: \"[[...],[...],[...],[...]]\"\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(csv_path, header=None)\n",
    "    \n",
    "    # Parse string lists into actual arrays\n",
    "    srs_data = []\n",
    "    for val in df[1]:  # assuming column 1 contains the lists\n",
    "        arr = np.array(ast.literal_eval(val), dtype=np.float32)  # shape (4, 1536)\n",
    "        srs_data.append(arr)\n",
    "    \n",
    "    srs_data = np.stack(srs_data, axis=0)  # shape (num_rows, 4, 1536)\n",
    "    \n",
    "    num_rows = srs_data.shape[0]\n",
    "    \n",
    "    for t in range(num_rows - input_rows - pred_offset + 1):\n",
    "        X_seq = srs_data[t:t+input_rows]  # shape (input_rows, 4, 1536)\n",
    "        # reshape to WxHxC\n",
    "        X_seq_reshaped = np.stack([x.reshape(W, H, 1536) for x in X_seq], axis=0)\n",
    "        \n",
    "        y = srs_data[t + input_rows + pred_offset - 1]  # shape (4, 1536)\n",
    "        yield X_seq_reshaped.astype(np.float32), y.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "7e03c778",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "\n",
    "def train_model(model, e2_csv, srs_csv, epochs=1, batch_size=1):\n",
    "    \"\"\"\n",
    "    Train the model using sliding window chunks from E2 and SRS CSVs.\n",
    "    Collects loss history for plotting.\n",
    "    \"\"\"\n",
    "    # Read CSVs\n",
    "    e2_rows = pd.read_csv(e2_csv).shape[0]\n",
    "    srs_rows = pd.read_csv(srs_csv, header=None).shape[0]\n",
    "    \n",
    "    # Define sliding window lengths\n",
    "    e2_len = 20\n",
    "    srs_input_rows = 70\n",
    "    pred_offset = 1  # predict next row\n",
    "\n",
    "    # Number of training steps\n",
    "    steps = min(e2_rows - e2_len, srs_rows - srs_input_rows - pred_offset + 1)\n",
    "\n",
    "    loss_history = []\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        print(f\"Epoch {epoch+1}/{epochs}\")\n",
    "\n",
    "        # Reset the SRS generator\n",
    "        srs_gen = load_srs_chunk(srs_csv, input_rows=srs_input_rows, pred_offset=pred_offset)\n",
    "\n",
    "        for step in range(steps):\n",
    "            # --- Load E2 chunk ---\n",
    "            X_e2 = load_e2_chunk(e2_csv, step, num_rows=e2_len)\n",
    "            X_e2_batch = np.expand_dims(X_e2, axis=0)  # add batch dim\n",
    "\n",
    "            # --- Load SRS chunk ---\n",
    "            try:\n",
    "                X_srs, y = next(srs_gen)\n",
    "            except StopIteration:\n",
    "                break  # generator exhausted\n",
    "            X_srs_batch = np.expand_dims(X_srs, axis=0)\n",
    "            y_batch = np.expand_dims(y, axis=0)\n",
    "\n",
    "            # --- Adjust SRS shape to match model input ---\n",
    "            # Example: model expects (20,20,1536)\n",
    "            # Here we crop/pad W/H if needed\n",
    "            target_W, target_H, target_C = model.input[1].shape[1:]  # srs_input_shape\n",
    "            X_srs_resized = X_srs_batch\n",
    "            if X_srs_batch.shape[1] != target_W or X_srs_batch.shape[2] != target_H:\n",
    "                # Simple crop or pad to match\n",
    "                X_srs_resized = X_srs_batch[:, :target_W, :target_H, :]\n",
    "\n",
    "            # --- Train step ---\n",
    "            loss = model.train_on_batch([X_e2_batch, X_srs_resized], y_batch)\n",
    "            loss_history.append(loss)\n",
    "\n",
    "            if (step+1) % 50 == 0 or step == steps-1:\n",
    "                print(f\"Step {step+1}/{steps}, Loss: {loss:.6f}\")\n",
    "\n",
    "    return loss_history\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "0f73f1e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers, models\n",
    "\n",
    "def create_model(e2_input_shape=(5, 4, 19), srs_input_shape=(20, 20, 1536), lstm_units=128, dropout_rate=0.3):\n",
    "    \n",
    "    radio_input = layers.Input(shape=e2_input_shape, name='radio_input')\n",
    "    \n",
    "    r1 = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(radio_input)  # use padded r1\n",
    "    r1 = layers.BatchNormalization()(r1)\n",
    "    r1 = layers.Conv2D(32, (2, 2), activation='relu', padding='same')(r1)\n",
    "    r1 = layers.BatchNormalization()(r1)\n",
    "    r1 = layers.Dropout(dropout_rate)(r1)\n",
    "    r1 = layers.ZeroPadding2D(padding=((0,0),(0,1)))(r1)  # pad width by 1\n",
    "\n",
    "    srs_input = layers.Input(shape=srs_input_shape, name='srs_input')\n",
    "    s1 = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(srs_input)\n",
    "    s1 = layers.Conv2D(1024, (1, 1), activation='relu', padding='same')(s1)\n",
    "    s1 = layers.BatchNormalization()(s1)\n",
    "    s1 = layers.MaxPooling2D((2, 2))(s1)\n",
    "    s1 = layers.Conv2D(32, (2, 2), activation='relu', padding='same')(s1)\n",
    "    s1 = layers.Conv2D(256, (1, 1), activation='relu', padding='same')(s1)\n",
    "    s1 = layers.Conv2D(128, (2, 2), activation='relu', padding='same')(s1)\n",
    "    s1 = layers.BatchNormalization()(s1)\n",
    "    s1 = layers.MaxPooling2D((2, 2))(s1)\n",
    "    s1 = layers.Conv2D(128, (1, 1), activation='relu', padding='same')(s1)\n",
    "    s1 = layers.Conv2D(64, (1, 1), activation='relu', padding='same')(s1)\n",
    "    s1 = layers.Dropout(dropout_rate)(s1)\n",
    "\n",
    "    # Concatenate and LSTM\n",
    "    x = layers.Concatenate(axis=-1)([r1, s1])\n",
    "    x = layers.Reshape((5*5, 32+64))(x)\n",
    "    x = layers.LSTM(lstm_units, return_sequences=True)(x)\n",
    "    x = layers.Flatten()(x)         \n",
    "    x = layers.Dense(4*1536)(x)      \n",
    "    output = layers.Reshape((4,1536))(x)\n",
    "\n",
    "    model = models.Model(inputs=[radio_input, srs_input], outputs=output)\n",
    "    model.compile(optimizer='adam', loss='mse')\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "96b4623f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_6\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " srs_input (InputLayer)         [(None, 20, 20, 153  0           []                               \n",
      "                                6)]                                                               \n",
      "                                                                                                  \n",
      " conv2d_65 (Conv2D)             (None, 20, 20, 64)   884800      ['srs_input[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_66 (Conv2D)             (None, 20, 20, 1024  66560       ['conv2d_65[0][0]']              \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_30 (BatchN  (None, 20, 20, 1024  4096       ['conv2d_66[0][0]']              \n",
      " ormalization)                  )                                                                 \n",
      "                                                                                                  \n",
      " max_pooling2d_14 (MaxPooling2D  (None, 10, 10, 1024  0          ['batch_normalization_30[0][0]'] \n",
      " )                              )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_67 (Conv2D)             (None, 10, 10, 32)   131104      ['max_pooling2d_14[0][0]']       \n",
      "                                                                                                  \n",
      " radio_input (InputLayer)       [(None, 5, 4, 19)]   0           []                               \n",
      "                                                                                                  \n",
      " conv2d_68 (Conv2D)             (None, 10, 10, 256)  8448        ['conv2d_67[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_63 (Conv2D)             (None, 5, 4, 64)     11008       ['radio_input[0][0]']            \n",
      "                                                                                                  \n",
      " conv2d_69 (Conv2D)             (None, 10, 10, 128)  131200      ['conv2d_68[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_28 (BatchN  (None, 5, 4, 64)    256         ['conv2d_63[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_31 (BatchN  (None, 10, 10, 128)  512        ['conv2d_69[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv2d_64 (Conv2D)             (None, 5, 4, 32)     8224        ['batch_normalization_28[0][0]'] \n",
      "                                                                                                  \n",
      " max_pooling2d_15 (MaxPooling2D  (None, 5, 5, 128)   0           ['batch_normalization_31[0][0]'] \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " batch_normalization_29 (BatchN  (None, 5, 4, 32)    128         ['conv2d_64[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv2d_70 (Conv2D)             (None, 5, 5, 128)    16512       ['max_pooling2d_15[0][0]']       \n",
      "                                                                                                  \n",
      " dropout_14 (Dropout)           (None, 5, 4, 32)     0           ['batch_normalization_29[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_71 (Conv2D)             (None, 5, 5, 64)     8256        ['conv2d_70[0][0]']              \n",
      "                                                                                                  \n",
      " zero_padding2d_7 (ZeroPadding2  (None, 5, 5, 32)    0           ['dropout_14[0][0]']             \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " dropout_15 (Dropout)           (None, 5, 5, 64)     0           ['conv2d_71[0][0]']              \n",
      "                                                                                                  \n",
      " concatenate_7 (Concatenate)    (None, 5, 5, 96)     0           ['zero_padding2d_7[0][0]',       \n",
      "                                                                  'dropout_15[0][0]']             \n",
      "                                                                                                  \n",
      " reshape_12 (Reshape)           (None, 25, 96)       0           ['concatenate_7[0][0]']          \n",
      "                                                                                                  \n",
      " lstm_6 (LSTM)                  (None, 25, 128)      115200      ['reshape_12[0][0]']             \n",
      "                                                                                                  \n",
      " flatten_6 (Flatten)            (None, 3200)         0           ['lstm_6[0][0]']                 \n",
      "                                                                                                  \n",
      " dense_6 (Dense)                (None, 6144)         19666944    ['flatten_6[0][0]']              \n",
      "                                                                                                  \n",
      " reshape_13 (Reshape)           (None, 4, 1536)      0           ['dense_6[0][0]']                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 21,053,248\n",
      "Trainable params: 21,050,752\n",
      "Non-trainable params: 2,496\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = create_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "09edc5fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "1",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\mdraf\\anaconda3\\envs\\py310\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3804\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3805\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3806\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32mindex.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mindex.pyx:196\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:2606\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.Int64HashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:2630\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.Int64HashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 1",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[51], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mP:/SP Challenge/DataSet/Preprocessed Dataset/E2_1.csv\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mP:/SP Challenge/DataSet/Preprocessed Dataset/pp_srs_1.csv\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[43m            \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[43m            \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[48], line 35\u001b[0m, in \u001b[0;36mtrain_model\u001b[1;34m(model, e2_csv, srs_csv, epochs, batch_size)\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[38;5;66;03m# --- Load SRS chunk ---\u001b[39;00m\n\u001b[0;32m     34\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 35\u001b[0m     X_srs, y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msrs_gen\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     36\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[0;32m     37\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m  \u001b[38;5;66;03m# generator exhausted\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[47], line 45\u001b[0m, in \u001b[0;36mload_srs_chunk\u001b[1;34m(csv_path, input_rows, pred_offset, W, H)\u001b[0m\n\u001b[0;32m     43\u001b[0m \u001b[38;5;66;03m# Parse string lists into actual arrays\u001b[39;00m\n\u001b[0;32m     44\u001b[0m srs_data \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m---> 45\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m val \u001b[38;5;129;01min\u001b[39;00m \u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m:  \u001b[38;5;66;03m# assuming column 1 contains the lists\u001b[39;00m\n\u001b[0;32m     46\u001b[0m     arr \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(ast\u001b[38;5;241m.\u001b[39mliteral_eval(val), dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mfloat32)  \u001b[38;5;66;03m# shape (4, 1536)\u001b[39;00m\n\u001b[0;32m     47\u001b[0m     srs_data\u001b[38;5;241m.\u001b[39mappend(arr)\n",
      "File \u001b[1;32mc:\\Users\\mdraf\\anaconda3\\envs\\py310\\lib\\site-packages\\pandas\\core\\frame.py:4102\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   4100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   4101\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 4102\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   4104\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[1;32mc:\\Users\\mdraf\\anaconda3\\envs\\py310\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3807\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[0;32m   3808\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[0;32m   3809\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[0;32m   3810\u001b[0m     ):\n\u001b[0;32m   3811\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[1;32m-> 3812\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3813\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   3814\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3815\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3816\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3817\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 1"
     ]
    }
   ],
   "source": [
    "train_model(model, \n",
    "            \"P:/SP Challenge/DataSet/Preprocessed Dataset/E2_1.csv\", \n",
    "            \"P:/SP Challenge/DataSet/Preprocessed Dataset/pp_srs_1.csv\", \n",
    "            epochs=3, \n",
    "            batch_size=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
